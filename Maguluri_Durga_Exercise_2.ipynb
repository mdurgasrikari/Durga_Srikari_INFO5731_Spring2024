{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdurgasrikari/Durga_Srikari_INFO5731_Spring2024/blob/main/Maguluri_Durga_Exercise_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DymRJbxDBCnf"
      },
      "source": [
        "# **INFO5731 In-class Exercise 2**\n",
        "\n",
        "The purpose of this exercise is to understand users' information needs, and then collect data from different sources for analysis by implementing web scraping using Python.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting research question (or practical question or something innovative) you have in mind, what kind of data should be collected to answer the question(s)? Specify the amount of data needed for analysis. Provide detailed steps for collecting and saving the data."
      ],
      "metadata": {
        "id": "FBKvD6O_TY6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Research Question\n",
        "\n",
        "#Internet crimes are on the rise and phishing is the most popular type of cybercrime.\n",
        "#Phishing is a form of internet crime where attackers deceive people into providing their data through a scam process.\n",
        "#In 2022, IC3(Internet Crime Complaint Center by FBI) recorded 847,376 complaints which accounted for a total loss of $10.3 Billion in the US alone.\n",
        "#Phishing accounted for more than 300,497 complaints with a total loss of $52,089,159.\n",
        "#User awareness and education is an important step to combat phishing.\n",
        "#However, this is not an efficient solution for the VIB community (Visually Impaired and Blind).\n",
        "#The focus of this research is to design an AI-based phishing detection model for the VIB community that uses smart devices.\n",
        "#The model utilizes Machine learning, AI detection capability, and voice-assisted features for detecting and mitigating phishing emails.\n",
        "\n",
        "#Proposed Solution\n",
        "\n",
        "#An AI model will be built with two components (Signature analysis and Sentiment Analysis). The model will analyze the URLS and emails\n",
        "#with the existing malicious repository (of pre detected  malicious emails and URLs).\n",
        "#The result will be risk score (Low, medium, and high) based on the match.This is part of the signature analysis.\n",
        "#The model analyzes the sentiment of the content of the email to determine to determine a score (Low, medium, and high).\n",
        "#These two scores are validated through a matrix and the email will be flagged based on the resultant score (Low, medium, high).\n",
        "#If a phishing email is detected, the VIB user will be alerted through a voice assitance to delete it with their confirmation\n",
        "\n",
        "\n",
        "#Data Needed\n",
        "\n",
        "#To train the model, we will need malicious and safe (URLs, email addresses, email content). This will help the model differentiate between\n",
        "#a phishing email and a safe email. Also, data of different emails (Spam, Fraud) along with phishing and safe emails should also be trained\n",
        "#so that the ai model can determine the difference and accurately determine the phishing emails.\n",
        "\n",
        "#Datasets\n",
        "#A minimum of a 1000 samples can be considered a good sample size to train the model and good start to understand the behavior of the model.\n",
        "#Based on the performance of the model, further large datasets will be provided as an input to finetune the model.\n",
        "\n",
        "#Data Analysis\n",
        "#While real project needed to be trained on real word email data. For this exercise and demo. We will use open-source datasets.\n",
        "#Data can be collected from open sources such as Github, Kaggle, etc. These may be raw data and hence preprocessing will be needed\n",
        "#The foundation of any data-centric project lies in the quality of its data. Preprocessing involves tokenizing emails, eliminating stop words\n",
        "#that do not add significant meaning, removing punctuations that might act as noise, and transforming all words to lowercase to maintain consistency.\n",
        "\n",
        "#Proposed preprocessing for the project\n",
        "#Encoding Labels:\n",
        "#Encode the email types into numerical labels (e.g., 0 for Safe Email and 1 for Phishing Email and 2) so that the model can understand them.\n",
        "#Data Cleaning:\n",
        "#Remove any duplicate emails if they exist in the dataset.\n",
        "#Converte all text to lowercase to ensure consistency in text processing.\n",
        "#Remove any leading or trailing white spaces.\n",
        "#Stop word & irrelevant character Removal:\n",
        "#Remove common stop words (e.g., \"the\", \"and\", \"in\") as they usually do not contribute to the identification of phishing emails.\n",
        "#Remove any special characters, symbols, HTML tags, and punctuation marks that may not provide valuable information for phishing detection.\n",
        "#Secure the result data in a secure database and anonymize any sensitive data.\n",
        "\n",
        "#For the purpose of this exercise, a data set from Github was retrived and displayed in the next question. Preprocessing was not performed\n",
        "#as it was not mentioned in the scope of the question. But, above stated preprocessing steps will be implementing in case of such a scope\n",
        "#provided.\n"
      ],
      "metadata": {
        "id": "cikVKDXdTbzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 2 (10 Points)\n",
        "Write Python code to collect a dataset of 1000 samples related to the question discussed in Question 1."
      ],
      "metadata": {
        "id": "E9RqrlwdTfvl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing pandas library\n",
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file into a pandas DataFrame with a different encoding\n",
        "url = \"https://github.com/TanusreeSharma/phishingdata-Analysis/raw/master/1st%20data/PhishingEmailData.csv\"\n",
        "df = pd.read_csv(url, encoding='latin1')\n",
        "\n",
        "# Select all the rows as a new dataset\n",
        "dataset_1000_samples = df\n",
        "\n",
        "# Displaying the first five rows of the new dataset for easy display and quick understanding as 1000 rows may take a lot of the page space\n",
        "dataset_1000_samples.head(5)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "xXSit3qUsmzh",
        "outputId": "2b07f7f0-2f92-409c-cb8b-0c159662e22b"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                      Email_Subject  \\\n",
              "0                                    URGENT REQUEST   \n",
              "1                                    Quick question   \n",
              "2  ******Part time home work assistant needed******   \n",
              "3                                  Ê vendor payment   \n",
              "4                                    Quick question   \n",
              "\n",
              "                                       Email_Content Sending_Date  \\\n",
              "0  Are you available ?\\nNo calls text only 951307...       1/9/20   \n",
              "1  I'm in a meeting and need help getting some Am...       1/9/20   \n",
              "2  Hello RECIPIENT\\n\\nI am urgently seeking for a...     10/19/19   \n",
              "3  Are you around? I need to pay a vendor with th...  12/27/18\\n    \n",
              "4  I'm in a meeting and need help getting some Am...  12/27/18\\n    \n",
              "\n",
              "  Sending_Time   Day URL_Title         Coined.Word Sender_Name  \\\n",
              "0           na    na        na              Urgent           Y   \n",
              "1           na    na        na               Quick           Y   \n",
              "2      2:22 PM   Sat        na          Job/Needed           Y   \n",
              "3           na    na        na  gift card, meeting           Y   \n",
              "4           na    na        na              shared           Y   \n",
              "\n",
              "                                        Sender_Title Closing_Remarks  \\\n",
              "0      Chancellor\\nBerkeley University of California    BEST REGARDS   \n",
              "1                 University of California, Berkeley              na   \n",
              "2  *Professor David Card*\\n*Department of Economi...     Sincerely     \n",
              "3                 University of California, Berkeley              na   \n",
              "4                 University of California, Berkeley              na   \n",
              "\n",
              "                            Sender_Email  Logo   To  \n",
              "0           cchristberkeley.edu@gmail.com   na   NB  \n",
              "1              XXX.subdomain.berkeley.edu   na   NB  \n",
              "2                   dvdmson @ gmail . Com   na   NB  \n",
              "3  ÊÊXXX.subdomain.berkeley.edu@gmail.com   na   NB  \n",
              "4              XXX.subdomain.berkeley.edu   na  NaN  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a36f6a4c-b9d7-4877-a5d4-45c5f5bd9277\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Email_Subject</th>\n",
              "      <th>Email_Content</th>\n",
              "      <th>Sending_Date</th>\n",
              "      <th>Sending_Time</th>\n",
              "      <th>Day</th>\n",
              "      <th>URL_Title</th>\n",
              "      <th>Coined.Word</th>\n",
              "      <th>Sender_Name</th>\n",
              "      <th>Sender_Title</th>\n",
              "      <th>Closing_Remarks</th>\n",
              "      <th>Sender_Email</th>\n",
              "      <th>Logo</th>\n",
              "      <th>To</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>URGENT REQUEST</td>\n",
              "      <td>Are you available ?\\nNo calls text only 951307...</td>\n",
              "      <td>1/9/20</td>\n",
              "      <td>na</td>\n",
              "      <td>na</td>\n",
              "      <td>na</td>\n",
              "      <td>Urgent</td>\n",
              "      <td>Y</td>\n",
              "      <td>Chancellor\\nBerkeley University of California</td>\n",
              "      <td>BEST REGARDS</td>\n",
              "      <td>cchristberkeley.edu@gmail.com</td>\n",
              "      <td>na</td>\n",
              "      <td>NB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Quick question</td>\n",
              "      <td>I'm in a meeting and need help getting some Am...</td>\n",
              "      <td>1/9/20</td>\n",
              "      <td>na</td>\n",
              "      <td>na</td>\n",
              "      <td>na</td>\n",
              "      <td>Quick</td>\n",
              "      <td>Y</td>\n",
              "      <td>University of California, Berkeley</td>\n",
              "      <td>na</td>\n",
              "      <td>XXX.subdomain.berkeley.edu</td>\n",
              "      <td>na</td>\n",
              "      <td>NB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>******Part time home work assistant needed******</td>\n",
              "      <td>Hello RECIPIENT\\n\\nI am urgently seeking for a...</td>\n",
              "      <td>10/19/19</td>\n",
              "      <td>2:22 PM</td>\n",
              "      <td>Sat</td>\n",
              "      <td>na</td>\n",
              "      <td>Job/Needed</td>\n",
              "      <td>Y</td>\n",
              "      <td>*Professor David Card*\\n*Department of Economi...</td>\n",
              "      <td>Sincerely</td>\n",
              "      <td>dvdmson @ gmail . Com</td>\n",
              "      <td>na</td>\n",
              "      <td>NB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ê vendor payment</td>\n",
              "      <td>Are you around? I need to pay a vendor with th...</td>\n",
              "      <td>12/27/18\\n</td>\n",
              "      <td>na</td>\n",
              "      <td>na</td>\n",
              "      <td>na</td>\n",
              "      <td>gift card, meeting</td>\n",
              "      <td>Y</td>\n",
              "      <td>University of California, Berkeley</td>\n",
              "      <td>na</td>\n",
              "      <td>ÊÊXXX.subdomain.berkeley.edu@gmail.com</td>\n",
              "      <td>na</td>\n",
              "      <td>NB</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quick question</td>\n",
              "      <td>I'm in a meeting and need help getting some Am...</td>\n",
              "      <td>12/27/18\\n</td>\n",
              "      <td>na</td>\n",
              "      <td>na</td>\n",
              "      <td>na</td>\n",
              "      <td>shared</td>\n",
              "      <td>Y</td>\n",
              "      <td>University of California, Berkeley</td>\n",
              "      <td>na</td>\n",
              "      <td>XXX.subdomain.berkeley.edu</td>\n",
              "      <td>na</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a36f6a4c-b9d7-4877-a5d4-45c5f5bd9277')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a36f6a4c-b9d7-4877-a5d4-45c5f5bd9277 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a36f6a4c-b9d7-4877-a5d4-45c5f5bd9277');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-afb16611-2c3a-45be-acc5-ec8501f46c83\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-afb16611-2c3a-45be-acc5-ec8501f46c83')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-afb16611-2c3a-45be-acc5-ec8501f46c83 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset_1000_samples",
              "summary": "{\n  \"name\": \"dataset_1000_samples\",\n  \"rows\": 189,\n  \"fields\": [\n    {\n      \"column\": \"Email_Subject\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"Last Reminder You Must Update Your Apple Account Information!\",\n          \"I AM ASKING FOR YOUR SUPPORT.\",\n          \"Preliminary CD and Other Closing Docs Attached Closing Set for 03/08/2019\"\n        ],\n        \"num_unique_values\": 184,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Email_Content\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"Hello Everyone,\\n \\n  There will be additional IT maintenance today between 10am \\u00d0 11am. During this time, some IT systems and applications used by the IRC globally may be affected, and you may experience brief outages. Please upgrade your mailboxes (size to 20.0GB). by clicking IT SYSTEM AND MAINTENANCE.\",\n          \"called missed\",\n          \"link for email opning\"\n        ],\n        \"num_unique_values\": 176,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sending_Date\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"June 2nd, 2019\",\n          \"April 16th, 2019\",\n          \"3/13/16\"\n        ],\n        \"num_unique_values\": 132,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sending_Time\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"9.47am\",\n          \"9.17am\",\n          \"10.22am\"\n        ],\n        \"num_unique_values\": 174,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Day\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"tue\",\n          \"Fri\",\n          \"na\"\n        ],\n        \"num_unique_values\": 15,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"URL_Title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"open doc\",\n          \"email\",\n          \"Sign in to customer portal\"\n        ],\n        \"num_unique_values\": 90,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coined.Word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"samples\": [\n          \"invoice, shared\",\n          \"TAX, W2, important\",\n          \"invoice,deleted, account\"\n        ],\n        \"num_unique_values\": 169,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sender_Name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"na\",\n          \"y\",\n          \"Y\"\n        ],\n        \"num_unique_values\": 4,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sender_Title\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"office 365 Customer Service\",\n          \"Help Desk\\u0089\\u00db\\u00dc\",\n          \"Colman\"\n        ],\n        \"num_unique_values\": 31,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Closing_Remarks\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"Cheers\",\n          \"Thanks for you Cooperation in Advance.\",\n          \"Sincerely,\"\n        ],\n        \"num_unique_values\": 37,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sender_Email \",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"support@ppl.com\",\n          \"Acces@up.com\",\n          \"records@dol.gov\"\n        ],\n        \"num_unique_values\": 32,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Logo\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"one drive\",\n          \"shadowshopper\",\n          \"SharePoint\"\n        ],\n        \"num_unique_values\": 30,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"To\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"BCC\",\n          \" B\",\n          \"B\"\n        ],\n        \"num_unique_values\": 5,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03jb4GZsBkBS"
      },
      "source": [
        "## Question 3 (10 Points)\n",
        "Write Python code to collect 1000 articles from Google Scholar (https://scholar.google.com/), Microsoft Academic (https://academic.microsoft.com/home), or CiteSeerX (https://citeseerx.ist.psu.edu/index), or Semantic Scholar (https://www.semanticscholar.org/), or ACM Digital Libraries (https://dl.acm.org/) with the keyword \"XYZ\". The articles should be published in the last 10 years (2014-2024).\n",
        "\n",
        "The following information from the article needs to be collected:\n",
        "\n",
        "(1) Title of the article\n",
        "\n",
        "(2) Venue/journal/conference being published\n",
        "\n",
        "(3) Year\n",
        "\n",
        "(4) Authors\n",
        "\n",
        "(5) Abstract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YaGLbSHHB8Ej",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d7555e1-5762-412f-8e21-09208fee2f09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article 1:\n",
            "\n",
            "Title: The XYZ states revisited\n",
            "Authors: CZ Yuan - International Journal of Modern Physics A, 2018 - World Scientific\n",
            "Venue/Year: CZ Yuan - International Journal of Modern Physics A, 2018 - World Scientific\n",
            "Abstract: The BESIII and the LHCb became the leading experiments in the study of the exotic states \n",
            "after the Belle and BaBar experiments finished their data taking in the first decade of this …\n",
            "\n",
            "==================================================\n",
            "\n",
            "Article 2:\n",
            "\n",
            "Title: The XYZ states: experimental and theoretical status and perspectives\n",
            "Authors: N Brambilla, S Eidelman, C Hanhart, A Nefediev… - Physics Reports, 2020 - Elsevier\n",
            "Venue/Year: N Brambilla, S Eidelman, C Hanhart, A Nefediev… - Physics Reports, 2020 - Elsevier\n",
            "Abstract: The quark model was formulated in 1964 to classify mesons as bound states made of a \n",
            "quark–antiquark pair, and baryons as bound states made of three quarks. For a long time all …\n",
            "\n",
            "==================================================\n",
            "\n",
            "Article 3:\n",
            "\n",
            "Title: An overview of XYZ new particles\n",
            "Authors: X Liu - Chinese Science Bulletin, 2014 - Springer\n",
            "Venue/Year: X Liu - Chinese Science Bulletin, 2014 - Springer\n",
            "Abstract: … (XYZ\\) have been announced by experiments after analyzing various processes. Until now, \n",
            "the family of \\(XYZ… In general, the observed \\(XYZ\\) states can be categorized into five groups, …\n",
            "\n",
            "==================================================\n",
            "\n",
            "Article 4:\n",
            "\n",
            "Title: The xyz algorithm for fast interaction search in high-dimensional data\n",
            "Authors: GA Thanei, N Meinshausen, RD Shah - Journal of Machine Learning …, 2018 - jmlr.org\n",
            "Venue/Year: GA Thanei, N Meinshausen, RD Shah - Journal of Machine Learning …, 2018 - jmlr.org\n",
            "Abstract: … In this section, we present a version of the xyz algorithm applicable in the special case \n",
            "where both X and Y are binary, so Xij ∈ {−1,1} and Yi ∈ {−1,1}. We build up to the algorithm in …\n",
            "\n",
            "==================================================\n",
            "\n",
            "Article 5:\n",
            "\n",
            "Title: Dynamical Picture for the Formation and Decay of the Exotic  Mesons\n",
            "Authors: SJ Brodsky, DS Hwang, RF Lebed - Physical Review Letters, 2014 - APS\n",
            "Venue/Year: SJ Brodsky, DS Hwang, RF Lebed - Physical Review Letters, 2014 - APS\n",
            "Abstract: We present a new dynamical picture that identifies the formation of the exotic c c-containing \n",
            "states XYZ with the confinement-induced hadronization of a rapidly separating pair of a …\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#importaing requests library to enable HTTP request, beautifulSoup library for web scrapping, and datatime for handling time and date operations\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "#Function google_scholar_scrapper uses base url and parameters to query Google Scholar for english articles within the time range 2014-2024\n",
        "def google_scholar_scraper(query, num_articles=10):\n",
        "    base_url = 'https://scholar.google.com/scholar'\n",
        "    params = {\n",
        "        'q': query,\n",
        "        'hl': 'en',\n",
        "        'as_sdt': '0,5',\n",
        "        'as_ylo': '2014',\n",
        "        'as_yhi': '2024'\n",
        "    }\n",
        "\n",
        "#Creating/ initializing the articles list\n",
        "    articles = []\n",
        "\n",
        "#for loop to make multiple HTTP requests to Google Scholar to retrieve the number of articles in increments of 10 adjusting the start parameter in the base url\n",
        "    for start in range(0, num_articles, 10):\n",
        "        params['start'] = start\n",
        "        response = requests.get(base_url, params=params)\n",
        "\n",
        "#If the HTTP response is 200 (Ok/Success), then beautifulsoap will parse the page and add the content present in the div section under the class gs_ri\n",
        "#which has the article information such as title, author etc.\n",
        "        if response.status_code == 200:\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            results = soup.find_all('div', {'class': 'gs_ri'})\n",
        "\n",
        "#for loop to iterate through the parsed search results to retrieve the title, author, year and abstract of the article\n",
        "            for result in results:\n",
        "                title = result.find('h3').text\n",
        "                authors = result.find('div', {'class': 'gs_a'}).text\n",
        "                venue_year = result.find('div', {'class': 'gs_a'}).text\n",
        "                abstract = result.find('div', {'class': 'gs_rs'})\n",
        "\n",
        "#if else condition to check if abstract is present fot the article or not\n",
        "                if abstract:\n",
        "                    abstract = abstract.text\n",
        "                else:\n",
        "                    abstract = None\n",
        "\n",
        "#appending the article information to articles list created earlier\n",
        "                articles.append({\n",
        "                    'title': title,\n",
        "                    'authors': authors,\n",
        "                    'venue_year': venue_year,\n",
        "                    'abstract': abstract\n",
        "                })\n",
        "\n",
        "#returing the value of articles list\n",
        "    return articles\n",
        "\n",
        "#Inititalizing the query variable with mentioned string in the question\n",
        "query = \"XYZ\"\n",
        "#Inititalizing the number of articles variable as 1000 as mentioned in the question\n",
        "num_articles = 1000\n",
        "#function call for scrapping the google scholar for the articles based on the question requirements\n",
        "articles = google_scholar_scraper(query, num_articles)\n",
        "\n",
        "# Print the first 5 articles for ease of display as 1000 records would take the entire page\n",
        "for i in range(5):\n",
        "    print(f\"Article {i+1}:\\n\")\n",
        "    print(f\"Title: {articles[i]['title']}\")\n",
        "    print(f\"Authors: {articles[i]['authors']}\")\n",
        "    print(f\"Venue/Year: {articles[i]['venue_year']}\")\n",
        "    print(f\"Abstract: {articles[i]['abstract']}\")\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jJDe71iLB616"
      },
      "source": [
        "## Question 4A (10 Points)\n",
        "Develop Python code to collect data from social media platforms like Reddit, Instagram, Twitter (formerly known as X), Facebook, or any other. Use hashtags, keywords, usernames, or user IDs to gather the data.\n",
        "\n",
        "\n",
        "\n",
        "Ensure that the collected data has more than four columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#installing praw package to enable access to Reddit API\n",
        "!pip install praw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V590EF-uxpdx",
        "outputId": "de6d6152-ca3f-4bd8-8738-a9fc60bd9230"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting praw\n",
            "  Downloading praw-7.7.1-py3-none-any.whl (191 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.0/191.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prawcore<3,>=2.1 (from praw)\n",
            "  Downloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
            "Collecting update-checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.7.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.1->praw) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.1->praw) (2024.2.2)\n",
            "Installing collected packages: update-checker, prawcore, praw\n",
            "Successfully installed praw-7.7.1 prawcore-2.4.0 update-checker-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing praw library\n",
        "import praw\n",
        "\n",
        "#Defining the function to get posts from reddit by passing input parameters\n",
        "def get_reddit_posts(subreddit, hashtag, client_id, client_secret, user_agent):\n",
        "\n",
        "# Authenticating with Reddit API\n",
        "    reddit = praw.Reddit(client_id=client_id,\n",
        "                         client_secret=client_secret,\n",
        "                         user_agent=user_agent)\n",
        "\n",
        "    # Search for posts in the specified subreddit with the given hashtag\n",
        "    search_query = f\"#{hashtag} site:reddit.com/r/{subreddit}\"\n",
        "    subreddit = reddit.subreddit(subreddit)\n",
        "    posts = subreddit.search(search_query, sort='new', syntax='lucene', time_filter='all')\n",
        "\n",
        "    # Print the titles and URLs of the matching posts\n",
        "    for post in posts:\n",
        "        print(f\"Title: {post.title}\")\n",
        "        print(f\"URL: {post.url}\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Values of the account client ID, client secret, user agent, subreddit name and hashtag for the webscrapping\n",
        "    client_id = \"your_client_id\"\n",
        "    client_secret = \"your_client_secret\"\n",
        "    user_agent = \"your_user_agent\"\n",
        "    subreddit_name = \"scarpe\"\n",
        "    hashtag = \"elonmusk\"\n",
        "\n",
        "#Function call to get reddit posts\n",
        "    get_reddit_posts(subreddit_name, hashtag, client_id, client_secret, user_agent)\n"
      ],
      "metadata": {
        "id": "TFnc5RsnxtuX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tweepy\n",
        "\n",
        "# Set up Twitter API credentials\n",
        "consumer_key = 'z5fbQGivlkKcClTmq5bqg2eg6'\n",
        "consumer_secret = 'WbzPKbsTtSsvknA2idXP4CpePSkC2A8Woin75ufGE1Ip6w5HWJ'\n",
        "access_token = '315716857-RWcZK9cuh2yZUsGyYUzjzLgC0lhtKrOPsRs16UtA'\n",
        "access_token_secret = 'kCFrvsCsGgAk2Xcr4TNiNZLUlChlvaSTI2Aqfc5Rh6IPm'\n",
        "\n",
        "# Authenticate with Twitter API\n",
        "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "# Defining the hashtag to search for\n",
        "hashtag = \"#elonmusk\"\n",
        "\n",
        "# Defining the number of tweets to retrieve\n",
        "num_tweets = 10\n",
        "\n",
        "# Retrieve tweets with the specified hashtag\n",
        "tweets = tweepy.Cursor(api.search_tweets, q=hashtag, lang=\"en\").items(num_tweets)\n",
        "\n",
        "# Print the tweets\n",
        "for tweet in tweets:\n",
        "    print(f\"{tweet.user.screen_name}: {tweet.text}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "TrdQESyizmkw",
        "outputId": "56a55dd4-0273-4954-d3e6-2fe6e629e83e"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Forbidden",
          "evalue": "403 Forbidden\n453 - You currently have access to a subset of Twitter API v2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.twitter.com/en/portal/product",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-4183c130ccc8>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# Print the tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mtweet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{tweet.user.screen_name}: {tweet.text}\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    287\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m             model = ModelParser().parse(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpagination_mode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payload_list'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'payload_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpayload_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpayload_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36msearch_tweets\u001b[0;34m(self, q, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0m_Twitter\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mdocumentation\u001b[0m \u001b[0mon\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mstandard\u001b[0m \u001b[0msearch\u001b[0m \u001b[0mAPI\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhttps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mdeveloper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcom\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0men\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtwitter\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0moverview\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1145\u001b[0m         \"\"\"\n\u001b[0;32m-> 1146\u001b[0;31m         return self.request(\n\u001b[0m\u001b[1;32m   1147\u001b[0m             'GET', 'search/tweets', endpoint_parameters=(\n\u001b[1;32m   1148\u001b[0m                 \u001b[0;34m'q'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'geocode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'lang'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'locale'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'result_type'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'count'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tweepy/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mUnauthorized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m403\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mForbidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mNotFound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mForbidden\u001b[0m: 403 Forbidden\n453 - You currently have access to a subset of Twitter API v2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.twitter.com/en/portal/product"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55W9AMdXCSpV"
      },
      "source": [
        "## Question 4B (10 Points)\n",
        "If you encounter challenges with Question-4 web scraping using Python, employ any online tools such as ParseHub or Octoparse for data extraction. Introduce the selected tool, outline the steps for web scraping, and showcase the final output in formats like CSV or Excel.\n",
        "\n",
        "\n",
        "\n",
        "Upload a document (Word or PDF File) in any shared storage (preferably UNT OneDrive) and add the publicly accessible link in the below code cell.\n",
        "\n",
        "Please only choose one option for question 4. If you do both options, we will grade only the first one"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "sZOhks1dXWEe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on Web Scraping and Data Collection**\n",
        "\n",
        "\n",
        "\n",
        "Please share your thoughts and feedback on the web scraping and data collection exercises you have completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on web scraping tasks. What were the key concepts or techniques you found most beneficial in understanding the process of extracting data from various online sources?\n",
        "\n",
        "\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in collecting data from certain websites, and how did you overcome them? If you opted for the non-coding option, share your experience with the chosen tool.\n",
        "\n",
        "\n",
        "\n",
        "Relevance to Your Field of Study: How might the ability to gather and analyze data from online sources enhance your work or research?\n",
        "\n",
        "**(no grading of your submission if this question is left unanswered)**"
      ],
      "metadata": {
        "id": "eqmHVEwaWhbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Write your response here.\n",
        "\n",
        "This assignment has been a good challenge to complete different questions that reflected the learnings from the past few weeks.\n",
        "Learning included how to implement  API calls in real world web scrapping applications. But, I was not comfortable sharing the secret keys\n",
        "for the account and would be beneficial if we can create an acccount for this purpose of this course.\n",
        "\n",
        "This may help in my field of the interest, i.e cybersecurity to find the misinformation spread for latest cyber news\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "akAVJn9YBTQT"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}