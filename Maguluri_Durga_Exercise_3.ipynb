{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mdurgasrikari/Durga_Srikari_INFO5731_Spring2024/blob/main/Maguluri_Durga_Exercise_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VdRwkJBn70nX"
      },
      "source": [
        "# **INFO5731 In-class Exercise 3**\n",
        "\n",
        "The purpose of this exercise is to explore various aspects of text analysis, including feature extraction, feature selection, and text similarity ranking.\n",
        "\n",
        "**Expectations**:\n",
        "*   Students are expected to complete the exercise during lecture period to meet the active participation criteria of the course.\n",
        "*   Use the provided .*ipynb* document to write your code & respond to the questions. Avoid generating a new file.\n",
        "*   Write complete answers and run all the cells before submission.\n",
        "*   Make sure the submission is \"clean\"; *i.e.*, no unnecessary code cells.\n",
        "*   Once finished, allow shared rights from top right corner (*see Canvas for details*).\n",
        "\n",
        "**Total points**: 40\n",
        "\n",
        "**Deadline**: This in-class exercise is due at the end of the day tomorrow, at 11:59 PM.\n",
        "\n",
        "**Late submissions will have a penalty of 10% of the marks for each day of late submission. , and no requests will be answered. Manage your time accordingly.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARqm7u6B70ne"
      },
      "source": [
        "## Question 1 (10 Points)\n",
        "Describe an interesting text classification or text mining task and explain what kind of features might be useful for you to build the machine learning model. List your features and explain why these features might be helpful. You need to list at least five different types of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VAZj4PHB70nf"
      },
      "outputs": [],
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "#Please write you answer here:\n",
        "'''\n",
        "For this assignment, I would like to choose the following text classification task: Sentiment analysis of movie reviews to determine if the movie review is positive or negative\n",
        "\n",
        "Introduction: Movies are a prominent entertainment medium for society. With the invention of digital mediums, movies are reviewed on various platforms. These reviews may be positive, negative\n",
        "or neutral.  Analyzing this data will result in valuable insights into audience opinion which will benefit the filmamakers\n",
        "to determine the future. The goal of this analysis is to determine the positive sentiment of a movie review.\n",
        "\n",
        "Proposal: Sentiment analysis for movie reviews can be achieved by creating a machine-learning model. For the model, implementing the following features might be useful\n",
        "\n",
        "1. Punctuation Analysis: Examine how punctuation is used in the text. The use of ellipses, question marks, and exclamation points can offer further context to the statement. For instance, a series of exclamation points (!!!) could denote enthusiasm or optimism, but ellipses (...) could allude to hesitancy or doubt.\n",
        "2. Text Preprocessing & Tokenization : Special characters removal and generating tokens. Tokens can be used with various other methods for comparision and can aid in sentiment analysis.\n",
        "3. Review Length: Sentiment can occasionally be inferred from a review's length, as expressed in words or characters. For example, reviews that are too brief could not have enough details to allow for a clear sentiment analysis, whereas reviews that are longer might have more complex expressions.\n",
        "4. Bag of Words(BOW): The \"bag-of-words\" model is a text representation that utilizes an unordered word collection (or \"bag\") as the foundation. In this case, it represents a collection of\n",
        "specific words in movie reviews, allowing the model to identify keywords that can determine positive or negative sentiment.\n",
        "5. Term Frequency - Inverse Document Frequency (TF-IDF): TF-IDF measures a word's significance to a document inside a corpus or collection while accounting for the fact that certain words are\n",
        "more common than others overall. In this case, it can identify the most common words and rare words used across different reviews.\n",
        "6. N-grams: A group of n consecutive words, numbers, symbols, and punctuation that appear in a text document is called an n-gram. In this case, capturing adjacent words would provide contextual\n",
        "information that would help in determing the sentiment of a movie review.\n",
        "7. Part-of-Speech (POS) tags: Marking a word in a text (corpus) as belonging to a specific part of speech based on its meaning and context is known as POS tagging. In this case, certain words\n",
        "such as very, extremely can help determine strong sentiment.\n",
        "\n",
        "Please note that the order is not in a specific order and only for demonstration of different features. The order does not determine ascending or descending for best features\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dEUjBE6C70nf"
      },
      "source": [
        "## Question 2 (10 Points)\n",
        "Write python code to extract these features you discussed above. You can collect a few sample text data for the feature extraction."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading the text"
      ],
      "metadata": {
        "id": "GGAoqOBWDNuz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage with your provided movie review.\n",
        "\n",
        "#To demonstarte the code, I am using a movie review of Encanto (2023). Following is the link I am using. https://www.imdb.com/title/tt2953050/reviews/?ref_=tt_ov_rt.\n",
        "\n",
        "encanto_review = '''Encanto is a creative movie featuring beautiful and vibrant animation. However, the story feels a little underdeveloped. While there are some magical and emotional moments, it seems as if they didn't know how to end the movie. The lack of a strong villain also makes this movie a little less compelling. Nevertheless, the music is fun, and we enjoyed watching Encanto together as a family.'''"
      ],
      "metadata": {
        "id": "_9URfsUjCDXo"
      },
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Punctuation Analysis"
      ],
      "metadata": {
        "id": "QRDX1TjICMBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This code performs the punctuation anlysis on the code and provides the count in descending order such that for example it can determine the positive sentiment if the \"!\" marks are more\n",
        "\n",
        "import string\n",
        "\n",
        "def moview_review_punctuation_analysis(review):\n",
        "    punctuation_counts = {p: review.count(p) for p in string.punctuation}\n",
        "    sorted_counts = sorted(punctuation_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "    return sorted_counts\n",
        "\n",
        "# Feature Extraction\n",
        "punctuation_analysis = moview_review_punctuation_analysis(encanto_review)\n",
        "\n",
        "# Display Results\n",
        "print(\"Punctuation Analysis (Sorted by Count):\")\n",
        "for punctuation, count in punctuation_analysis:\n",
        "    print(f\"{punctuation}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uho6aTCgCa1g",
        "outputId": "0a01d2c1-a62b-4c32-e156-93d153d3f018"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Punctuation Analysis (Sorted by Count):\n",
            ".: 5\n",
            ",: 4\n",
            "': 1\n",
            "!: 0\n",
            "\": 0\n",
            "#: 0\n",
            "$: 0\n",
            "%: 0\n",
            "&: 0\n",
            "(: 0\n",
            "): 0\n",
            "*: 0\n",
            "+: 0\n",
            "-: 0\n",
            "/: 0\n",
            ":: 0\n",
            ";: 0\n",
            "<: 0\n",
            "=: 0\n",
            ">: 0\n",
            "?: 0\n",
            "@: 0\n",
            "[: 0\n",
            "\\: 0\n",
            "]: 0\n",
            "^: 0\n",
            "_: 0\n",
            "`: 0\n",
            "{: 0\n",
            "|: 0\n",
            "}: 0\n",
            "~: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Length"
      ],
      "metadata": {
        "id": "GnQ2gcHbExI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This code provides the sentence that may determine neutral sentiments. For example, if the review says \"Okay. \"It is alright\". These short sentences cannot determine positive or\n",
        "#negative sentiments. In such cases these sentiments can be determined as neutral sentiments.\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "def movie_review_sentence_length(review):\n",
        "    sentences = sent_tokenize(review)\n",
        "    return sum(len(sentence.split()) for sentence in sentences) / len(sentences) if len(sentences) > 0 else 0\n",
        "\n",
        "# Feature Extraction\n",
        "sentence_length = movie_review_sentence_length(encanto_review)\n",
        "\n",
        "# Display Results\n",
        "print(\"Moview Review's Sentence Length:\", sentence_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AoDHxqlWEVVt",
        "outputId": "55813620-bd4b-47c3-f9d1-0d44d5113e61"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moview Review's Sentence Length: 13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing Special characters, commas, any other characters apart from alphabets"
      ],
      "metadata": {
        "id": "34LJIBdIBXf5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "EoQX5s4O70nf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbfc2c63-3293-49f8-d4c3-302da7de34c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encanto is a creative movie featuring beautiful and vibrant animation However the story feels a little underdeveloped While there are some magical and emotional moments it seems as if they didnt know how to end the movie The lack of a strong villain also makes this movie a little less compelling Nevertheless the music is fun and we enjoyed watching Encanto together as a family\n"
          ]
        }
      ],
      "source": [
        "#Removing all characters except for alphabetic letters will provide clean data for the next processing steps.\n",
        "import re\n",
        "def Cleaned_Movie_Review_Text(text):\n",
        "    # Remove special characters, commas, numbers, and any other characters apart from alphabets\n",
        "    cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    return cleaned_text\n",
        "\n",
        "####\n",
        "encanto_review_text = Cleaned_Movie_Review_Text(encanto_review)\n",
        "\n",
        "print(encanto_review_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bag of Words"
      ],
      "metadata": {
        "id": "tPvbx3qeDwkt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#For this example, I am checking if the movie review has any extremely positive words\n",
        "extreme_positive_keywords = [\"milestone\", \"enchantment\", \"magical\", \"positive\", \"interesting\", \"appreciated\", \"enjoyed\", \"spectacular\", \"vibrant\", \"inventive\", \"dazzling\", \"exuberant\", \"catchy\", \"infectious\", \"wonderful\", \"excel\", \"winning\", \"loved\", \"amuses\", \"heart\", \"lovely\"]\n"
      ],
      "metadata": {
        "id": "NClmkbT4k31M"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Tokenize and count words\n",
        "word_counts = {word: 0 for word in extreme_positive_keywords}\n",
        "\n",
        "# Tokenize the review\n",
        "review_tokens = encanto_review_text.lower().split()\n",
        "\n",
        "# Count word occurrences for bag of words\n",
        "for i in review_tokens:\n",
        "    if i in word_counts:\n",
        "        word_counts[i] += 1\n",
        "\n",
        "# Display the word counts for bag of words\n",
        "for word, count in word_counts.items():\n",
        "    print( f\"{word}: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxDdbziQf8kK",
        "outputId": "b8a3b695-5115-499f-b7f3-9e373c1c402e"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "milestone: 0\n",
            "enchantment: 0\n",
            "magical: 1\n",
            "positive: 0\n",
            "interesting: 0\n",
            "appreciated: 0\n",
            "enjoyed: 1\n",
            "spectacular: 0\n",
            "vibrant: 1\n",
            "inventive: 0\n",
            "dazzling: 0\n",
            "exuberant: 0\n",
            "catchy: 0\n",
            "infectious: 0\n",
            "wonderful: 0\n",
            "excel: 0\n",
            "winning: 0\n",
            "loved: 0\n",
            "amuses: 0\n",
            "heart: 0\n",
            "lovely: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TF_IDF"
      ],
      "metadata": {
        "id": "sx67voQCFOcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#The below code demonstrates Tf-IDF to determine the frequency of the words in the movie review\n",
        "from typing_extensions import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#TF-IDF\n",
        "frequency= Counter(review_tokens)\n",
        "# Display the term frequency\n",
        "for word, count in frequency.most_common():\n",
        "    print(f\"{word}: {count}\")\n",
        "\n",
        "# Display the total number of words\n",
        "total_words = sum(frequency.values())\n",
        "print(f\"Total Words: {total_words}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-J6Suh8luoM",
        "outputId": "697b06cb-dc75-48c8-e317-9e7c9b26e349"
      },
      "execution_count": 177,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a: 5\n",
            "the: 4\n",
            "movie: 3\n",
            "and: 3\n",
            "encanto: 2\n",
            "is: 2\n",
            "little: 2\n",
            "as: 2\n",
            "creative: 1\n",
            "featuring: 1\n",
            "beautiful: 1\n",
            "vibrant: 1\n",
            "animation: 1\n",
            "however: 1\n",
            "story: 1\n",
            "feels: 1\n",
            "underdeveloped: 1\n",
            "while: 1\n",
            "there: 1\n",
            "are: 1\n",
            "some: 1\n",
            "magical: 1\n",
            "emotional: 1\n",
            "moments: 1\n",
            "it: 1\n",
            "seems: 1\n",
            "if: 1\n",
            "they: 1\n",
            "didnt: 1\n",
            "know: 1\n",
            "how: 1\n",
            "to: 1\n",
            "end: 1\n",
            "lack: 1\n",
            "of: 1\n",
            "strong: 1\n",
            "villain: 1\n",
            "also: 1\n",
            "makes: 1\n",
            "this: 1\n",
            "less: 1\n",
            "compelling: 1\n",
            "nevertheless: 1\n",
            "music: 1\n",
            "fun: 1\n",
            "we: 1\n",
            "enjoyed: 1\n",
            "watching: 1\n",
            "together: 1\n",
            "family: 1\n",
            "Total Words: 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "N grmas"
      ],
      "metadata": {
        "id": "WxkXvhOHFRNN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Below code demonstrates n-grams that can provide contextual relation between adjacent words.\n",
        "from nltk import ngrams\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Generate and display N-grams (here, N=2 for bigrams)\n",
        "n = 2\n",
        "bigrams = list(ngrams(review_tokens, n))\n",
        "\n",
        "# Display the bigrams\n",
        "print(f\"\\nBigrams:\")\n",
        "for bigram in bigrams:\n",
        "    print(bigram)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "heJ_yOwZmn3P",
        "outputId": "5a6e52f7-5cea-43e5-8058-80f200215b3a"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bigrams:\n",
            "('encanto', 'is')\n",
            "('is', 'a')\n",
            "('a', 'creative')\n",
            "('creative', 'movie')\n",
            "('movie', 'featuring')\n",
            "('featuring', 'beautiful')\n",
            "('beautiful', 'and')\n",
            "('and', 'vibrant')\n",
            "('vibrant', 'animation')\n",
            "('animation', 'however')\n",
            "('however', 'the')\n",
            "('the', 'story')\n",
            "('story', 'feels')\n",
            "('feels', 'a')\n",
            "('a', 'little')\n",
            "('little', 'underdeveloped')\n",
            "('underdeveloped', 'while')\n",
            "('while', 'there')\n",
            "('there', 'are')\n",
            "('are', 'some')\n",
            "('some', 'magical')\n",
            "('magical', 'and')\n",
            "('and', 'emotional')\n",
            "('emotional', 'moments')\n",
            "('moments', 'it')\n",
            "('it', 'seems')\n",
            "('seems', 'as')\n",
            "('as', 'if')\n",
            "('if', 'they')\n",
            "('they', 'didnt')\n",
            "('didnt', 'know')\n",
            "('know', 'how')\n",
            "('how', 'to')\n",
            "('to', 'end')\n",
            "('end', 'the')\n",
            "('the', 'movie')\n",
            "('movie', 'the')\n",
            "('the', 'lack')\n",
            "('lack', 'of')\n",
            "('of', 'a')\n",
            "('a', 'strong')\n",
            "('strong', 'villain')\n",
            "('villain', 'also')\n",
            "('also', 'makes')\n",
            "('makes', 'this')\n",
            "('this', 'movie')\n",
            "('movie', 'a')\n",
            "('a', 'little')\n",
            "('little', 'less')\n",
            "('less', 'compelling')\n",
            "('compelling', 'nevertheless')\n",
            "('nevertheless', 'the')\n",
            "('the', 'music')\n",
            "('music', 'is')\n",
            "('is', 'fun')\n",
            "('fun', 'and')\n",
            "('and', 'we')\n",
            "('we', 'enjoyed')\n",
            "('enjoyed', 'watching')\n",
            "('watching', 'encanto')\n",
            "('encanto', 'together')\n",
            "('together', 'as')\n",
            "('as', 'a')\n",
            "('a', 'family')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pos tagging"
      ],
      "metadata": {
        "id": "nYoIcGKHFXVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#POS tagging can help determine adjectives and can help in understanding the extreme sentiments of a review\n",
        "import nltk\n",
        "\n",
        "def review_pos_tag(review):\n",
        "    Review_Analysis_POS_tags = {'Noun': 0, 'Verb': 0, 'Adjective': 0, 'Adverb': 0}\n",
        "    pos_tags = nltk.pos_tag(nltk.word_tokenize(review))\n",
        "    for word, tag in pos_tags:\n",
        "        if tag.startswith('N'):\n",
        "            Review_Analysis_POS_tags['Noun'] += 1\n",
        "        elif tag.startswith('V'):\n",
        "            Review_Analysis_POS_tags['Verb'] += 1\n",
        "        elif tag.startswith('J'):\n",
        "            Review_Analysis_POS_tags['Adjective'] += 1\n",
        "        elif tag.startswith('R'):\n",
        "            Review_Analysis_POS_tags['Adverb'] += 1\n",
        "    return Review_Analysis_POS_tags\n",
        "\n",
        "# Example usage with a single review text\n",
        "result = review_pos_tag(encanto_review)\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ntlO0v0-F6zm",
        "outputId": "bbde4f4b-925d-4f35-df8b-2ce7b444981c"
      },
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Noun': 13, 'Verb': 14, 'Adjective': 10, 'Adverb': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7oSK4soH70nf"
      },
      "source": [
        "## Question 3 (10 points):\n",
        "Use any of the feature selection methods mentioned in this paper \"Deng, X., Li, Y., Weng, J., & Zhang, J. (2019). Feature selection for text classification: A review. Multimedia Tools & Applications, 78(3).\"\n",
        "\n",
        "Select the most important features you extracted above, rank the features based on their importance in the descending order."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "There are various feature selection techniques based on the research paper and also that are outlined in the above question that can be used in sentiment analysis namely,\n",
        "POS tagging, TF-IDf, N-grams, etc. However, when it is required to rank these features based on their importance in descending order can depend on a specific task and the data set given.\n",
        "\n",
        "Generally, to identify the importance of the features in sentiment analysis following factors should be taken into context.Task-specific context: The importance of feature selection methods\n",
        "can vary depending on the context of the task at hand.\n",
        "\n",
        "For example, if movie reviews have more punctuation marks like exclamation marks (!!!) which might indicate excitement or positivity, while ellipses (...) could suggest hesitation or\n",
        "uncertainty. For this kind of data punctuation analysis could be a more predominant feature selection method.\n",
        "For example, if the movie reviews have more emojis then using Emoji Analysis would be preferable as the most important feature selection method.\n",
        "\n",
        "Domain-Specific Context: Having a good understanding of the data and domain is very crucial for building a sentiment analytical model as few domains may have very specific\n",
        "keywords or phrases that could potentially play an important role. Knowing this beforehand could help in selecting the right feature selection methods.\n",
        "For example, Airline data has very specific keywords like delayed boarding, mishandled baggage, and flight cancellation which could be part of the corpus for the\n",
        "bag of words (BOW) method and can help in efficiently identifying the right keywords for sentiment analysis. Similarly, Parts-of-speech (POS) analysis can help in capturing the\n",
        "domain-specific keywords in the movie industry that can help in identifying sentiment accurately.\n",
        "\n",
        "Statistical Significance: Knowing the statistical significance of features in identifying sentiment for product reviews in an e-commerce company could be very helpful.\n",
        "For example, Chi-square can help in identifying features that are statistically significant for sentiment analysis.\n",
        "\n",
        "Machine learning model context: Relying on ML models for sentiment analysis could be another factor to be considered for assessing the importance of feature selection methods.\n",
        "For example, companies using ML models to optimize sentiment analysis algorithms for various business requirements could use a linear measure or HybridBest methods as the most\n",
        "predominant feature selection method.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "h36vEExScrZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nZGAOwl70ng"
      },
      "source": [
        "## Question 4 (10 points):\n",
        "Write python code to rank the text based on text similarity. Based on the text data you used for question 2, design a query to match the most relevant docments. Please use the BERT model to represent both your query and the text data, then calculate the cosine similarity between the query and each text in your data. Rank the similary with descending order."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "b4HoWK-i70ng",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "119e7582-0b9a-4314-97e7-a1779217cff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.10/dist-packages (2.5.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.32.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.38.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (2.1.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence-transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence-transformers) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.32.0->sentence-transformers) (0.4.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers) (3.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#This code determines the similarity score of queries and the text used.\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Sample text data\n",
        "text_data = [\n",
        "    \"Somehow I feel like this movie isn't finished. I see a lot of great work, and good ideas. But the story feels unfinished. This is most notible when we have the highpoint of the conflict in the last scene of the 2nd act. And this conflict is resolved the very next scene. And I can't help but feel that this story had so much more to explore. I could have seen this movie surpas coco, with it's more original story, but alas.\",\n",
        "    \"David Beckham is one of Britain's most iconic athletes whose name is also an elite global advertising brand. He was captain of the English national team from 2000 to 2009, scored in three different FIFA World Cups, and played midfield for clubs in Manchester, England, Madrid, Spain, and Milan, Italy; he also won the MLS Cup playing for Los Angeles Galaxy in 2011 and 2012.\",\n",
        "     \"I live in Dallas and I am currently a student in UNT\",\n",
        "    \"The music and the performances of the main characters are very good. Whilst it was entertaining and thought provoking I would have liked a bit more of an introduction to the members of the wailers. They were very much in the background and I we didn't really get to see Bob's relationship with the band members.The interactions with his wife, manager and record producer felt quite awkward (maybe they were?) Whilst it was quite formulaic (musical biopics like Ray and Respect have a very similar feel) I thoroughly enjoyed the film and I was surprised at how quickly we arrived at the final scenes,\",\n",
        "\n",
        "    #Below is my text used in question 2\n",
        "    \"Encanto is a creative movie featuring beautiful and vibrant animation. However, the story feels a little underdeveloped. While there are some magical and emotional moments, it seems as if they didn't know how to end the movie. The lack of a strong villain also makes this movie a little less compelling. Nevertheless, the music is fun, and we enjoyed watching Encanto together as a family.\"\n",
        "\n",
        "    ]\n",
        "\n",
        "# Sample query\n",
        "query = \"Encanto tells the tale of an extraordinary family, the Madrigals, who live hidden in the mountains of Colombia, in a magical house, in a vibrant town, in a wondrous, charmed place called an Encanto. The magic of the Encanto has blessed every child in the family with a unique gift from super strength to the power to heal-every child except one, Mirabel. But when she discovers that the magic surrounding the Encanto is in danger, Mirabel decides that she, the only ordinary Madrigal, might just be her exceptional family's last hope.\"\n",
        "\n",
        "\n",
        "# Load pre-trained BERT model and tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize and obtain embeddings for the query\n",
        "query_tokens = tokenizer(query, return_tensors='pt')\n",
        "with torch.no_grad():\n",
        "    query_outputs = model(**query_tokens)\n",
        "query_embedding = query_outputs['last_hidden_state'].mean(dim=1).numpy()\n",
        "\n",
        "# Calculate cosine similarity for each document\n",
        "similarities = []\n",
        "for document in text_data:\n",
        "    document_tokens = tokenizer(document, return_tensors='pt')\n",
        "    with torch.no_grad():\n",
        "        document_outputs = model(**document_tokens)\n",
        "    document_embedding = document_outputs['last_hidden_state'].mean(dim=1).numpy()\n",
        "    similarity = cosine_similarity(query_embedding, document_embedding)[0][0]\n",
        "    similarities.append(similarity)\n",
        "\n",
        "# Rank documents based on similarity\n",
        "ranked_indices = np.argsort(similarities)[::-1]\n",
        "\n",
        "# Print the ranked documents. This scores shows that the reviews related encanto are above 75%, the other reviews/queries are below 75%. Please note that when trained large data models\n",
        "#we can see a significant difference in the similarity scores.\n",
        "print(\"Rank\\tSimilarity\\tDocument\")\n",
        "for rank, index in enumerate(ranked_indices):\n",
        "    print(f\"{rank + 1}\\t{similarities[index]:.4f}\\t\\t{text_data[index]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NkRONYgD1bb_",
        "outputId": "b8564844-b5b1-43d4-8841-f51dc68bcffa"
      },
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank\tSimilarity\tDocument\n",
            "1\t0.7785\t\tEncanto is a creative movie featuring beautiful and vibrant animation. However, the story feels a little underdeveloped. While there are some magical and emotional moments, it seems as if they didn't know how to end the movie. The lack of a strong villain also makes this movie a little less compelling. Nevertheless, the music is fun, and we enjoyed watching Encanto together as a family.\n",
            "2\t0.7747\t\tSomehow I feel like this movie isn't finished. I see a lot of great work, and good ideas. But the story feels unfinished. This is most notible when we have the highpoint of the conflict in the last scene of the 2nd act. And this conflict is resolved the very next scene. And I can't help but feel that this story had so much more to explore. I could have seen this movie surpas coco, with it's more original story, but alas.\n",
            "3\t0.7140\t\tDavid Beckham is one of Britain's most iconic athletes whose name is also an elite global advertising brand. He was captain of the English national team from 2000 to 2009, scored in three different FIFA World Cups, and played midfield for clubs in Manchester, England, Madrid, Spain, and Milan, Italy; he also won the MLS Cup playing for Los Angeles Galaxy in 2011 and 2012.\n",
            "4\t0.6860\t\tThe music and the performances of the main characters are very good. Whilst it was entertaining and thought provoking I would have liked a bit more of an introduction to the members of the wailers. They were very much in the background and I we didn't really get to see Bob's relationship with the band members.The interactions with his wife, manager and record producer felt quite awkward (maybe they were?) Whilst it was quite formulaic (musical biopics like Ray and Respect have a very similar feel) I thoroughly enjoyed the film and I was surprised at how quickly we arrived at the final scenes,\n",
            "5\t0.5533\t\tI live in Dallas and I am currently a student in UNT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mandatory Question"
      ],
      "metadata": {
        "id": "VEs-OoDEhTW4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important: Reflective Feedback on this exercise**\n",
        "\n",
        "Please provide your thoughts and feedback on the exercises you completed in this assignment. Consider the following points in your response:\n",
        "\n",
        "Learning Experience: Describe your overall learning experience in working on extracting features from text data. What were the key concepts or techniques you found most beneficial in understanding the process?\n",
        "\n",
        "Challenges Encountered: Were there specific difficulties in completing this exercise?\n",
        "\n",
        "Relevance to Your Field of Study: How does this exercise relate to the field of NLP?\n",
        "\n",
        "**(Your submission will not be graded if this question is left unanswered)**\n",
        "\n"
      ],
      "metadata": {
        "id": "IUKC7suYhVl0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Your answer here (no code for this question, write down your answer as detail as possible for the above questions):\n",
        "\n",
        "'''\n",
        "Learning Experience: While working on this exercise. The first thing I did was to understand the requirements of the first question which forms the foundation of the entire exercise.\n",
        "I have selected the use case of movie reviews to provide sentiment analysis for each review. I had to research a lot to find the right set of feature selection methods that can determine\n",
        "the sentiment of a movie review accurately. Based on my research, I selected both foundational and technical features that can help in determining the sentiment with higher accuracy.\n",
        "\n",
        "For the purpose of this exercise, I selected the following feature selection methods namely, punctuation analysis, text preprocessing and tokenization, review length, bag of words,\n",
        "n-grams, POS tagging, and Tf-IDF to demonstrate the use of these methods for sentiment analysis. The give methods not in a particular order based on importance but randomly ordered.\n",
        "\n",
        "Challenges: The questions can be more specific which can help provide more focused code. The link to the research paper (question 3) does not allow to download full text.\n",
        "\n",
        "This exercise provides the overview of how different features can determine the sentiment analysis of a dataset given (for example movie reviews data in this case).\n",
        "The learnings from the exercise can also be applied to various other applications like building a sentiment analytical model for social media comments, product reviews etc.\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "CAq0DZWAhU9m"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}